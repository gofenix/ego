<html>
    <head>
        <title> 
            一致性哈希算法
        </title>

    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/styles/default.min.css"
    />
    <script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/highlight.min.js"></script>

    <script>
      hljs.highlightAll();
    </script>

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      .markdown-body {
        box-sizing: border-box;
        min-width: 200px;
        max-width: 980px;
        margin: 0 auto;
        padding: 45px;
      }

      @media (max-width: 767px) {
        .markdown-body {
          padding: 15px;
        }
      }
    </style>
    </head>

    <body>
        <div>
            <article class="markdown-body"> 
                <hr class="thin" />
<p>
date: “2018-03-24 19:03:58”
title: 一致性哈希算法</p>
<hr class="thin" />
<p>
当我们在做数据库分库分表或者做分布式缓存的时候，不可避免的都会遇到一个问题：</p>
<p>
<strong>如何将数据均匀的分散到各个节点中，并且尽量的在加减节点的时能使受影响的数据最少。</strong></p>
<h2>
1 hash取模</h2>
<p>
随机放置就不多说了。通常最容易想到的方案是哈希取模了。</p>
<p>
可以将传入的key按照
$$
index=hash(key) \% N
$$
这样来计算出需要存放的节点。</p>
<p>
这样可以满足数据的均匀分配，但是这个算法的容错性和扩展性比较差。比如增加或者删除一个节点的时候，所有的key都要重新计算，显然这样的成本比较高，为此需要一个算法来满足均匀的同时也要有良好的容错性和扩展性。</p>
<h2>
2 一致性hash算法</h2>
<p>
一致性hash算法是将所有的哈希值构成了一个环，其范围是0~2^32-1。如图：</p>
<p>
  <img src="https://ws1.sinaimg.cn/large/006tNc79gy1fn8kbmd4ncj30ad08y3yn.jpg" alt="哈希环" />
</p>
<p>
之后将各个服务器节点散列到这个环上，可以用节点的IP，hostname这样唯一性的字段作为key进行hash。散列之后如下：</p>
<p>
  <img src="https://ws3.sinaimg.cn/large/006tNc79gy1fn8kf72uwuj30a40a70t5.jpg" alt="" />
</p>
<p>
之后需要将数据定位到对应的节点上，使用同样的hash函数将key也映射到这个环上。</p>
<p>
  <img src="https://ws3.sinaimg.cn/large/006tNc79gy1fn8kj9kd4oj30ax0aomxq.jpg" alt="" />
</p>
<p>
这样就按照顺时针方向就可以将k1定位到N1节点，k2定位到N3节点，k3定位到N2节点。</p>
<h3>
2.1 容错性</h3>
<p>
假设N1宕机了：</p>
<p>
  <img src="https://ws3.sinaimg.cn/large/006tNc79gy1fn8kl9pp06j30a409waaj.jpg" alt="" />
</p>
<p>
依然根据顺时针方向，k2和k3保持不变，只有k1被重新映射到了N3。这样就很好的保证了容错性，当一个节点宕机时只会影响到少部分数据。</p>
<h3>
2.2 扩展性</h3>
<p>
当新增一个节点时：</p>
<p>
  <img src="https://ws1.sinaimg.cn/large/006tNc79gy1fn8kp1fc9xj30ca0abt9c.jpg" alt="" />
</p>
<p>
在N2和N3之间新增了一个节点N4，这时受影响的数据只有k3，其余的数据也是保持不变。</p>
<h3>
2.3 虚拟节点</h3>
<p>
到目前为止，该算法也有一些问题：</p>
<p>
当节点较少的时候可能出现数据不均匀的情况：</p>
<p>
  <img src="https://ws2.sinaimg.cn/large/006tNc79gy1fn8krttekbj30c10a5dg5.jpg" alt="" />
</p>
<p>
这样会导致大部分数据都在N1节点，只有少量的数据在N2节点。</p>
<p>
为了解决这个问题，一致性哈希算法引入了虚拟节点。</p>
<p>
将每一个节点进行多次哈希，生成的节点放置在环上成为<strong>虚拟节点</strong>。</p>
<p>
  <img src="https://ws2.sinaimg.cn/large/006tNc79gy1fn8ktzuswkj30ae0abdgb.jpg" alt="" />
</p>
<p>
计算时可以在 IP 后加上编号来生成哈希值。</p>
<p>
这样只需要在原有的基础上多一步由虚拟节点映射到实际节点的步骤即可让少量节点也能满足均匀性。</p>
<h2>
3 参考</h2>
<p>
<a href="https://crossoverjie.top/2018/01/08/Consistent-Hash/#more">https://crossoverjie.top/2018/01/08/Consistent-Hash/#more</a></p>

            </article>
        </div>
    </body>
</html>

    